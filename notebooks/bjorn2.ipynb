{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import torch  \n",
    "from Bio import SeqIO, AlignIO, Align, Seq\n",
    "import mutations as bm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n",
      "1\n",
      "Quadro P5000\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_fp = '/valhalla/gisaid/sequences_2021-02-21_aligned.fasta'\n",
    "patient_zero = 'NC_045512.2'\n",
    "seqs = SeqIO.parse(msa_fp, 'fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_rna(sequence: str):\n",
    "    \"encode nucleotide sequence as 4-bit vector\"\n",
    "    code = {\n",
    "            '-': -1,\n",
    "            'N': 0,\n",
    "            'A': 1,\n",
    "            'C': 2,\n",
    "            'T': 3,\n",
    "            'G': 4\n",
    "    }\n",
    "    return [code.get(nt, 0) for nt in sequence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10002"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load sample data from GISAID and encode\n",
    "data = []\n",
    "for i, rec in enumerate(seqs):\n",
    "    data.append(encode_rna(str(rec.seq)))\n",
    "    if i >= 10000:\n",
    "        break\n",
    "# add reference\n",
    "ref = bm.get_seq(seqs, patient_zero)\n",
    "data.append(encode_rna(ref))\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29903"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "max_len = 0\n",
    "for seq in data:\n",
    "    if len(seq)>max_len:\n",
    "        max_len = len(seq)\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29903"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "min_len = 100000\n",
    "for seq in data:\n",
    "    if len(seq)<min_len:\n",
    "        min_len = len(seq)\n",
    "min_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sequences into GPU\n",
    "data_tensor = torch.as_tensor(data, \n",
    "                              dtype=torch.int8, \n",
    "                              device=torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1, -1, -1,  ..., -1, -1, -1],\n",
       "        [-1, -1, -1,  ...,  1,  1,  1],\n",
       "        [-1, -1, -1,  ...,  1,  1,  1],\n",
       "        ...,\n",
       "        [-1, -1, -1,  ..., -1, -1, -1],\n",
       "        [-1, -1, -1,  ..., -1, -1, -1],\n",
       "        [ 1,  3,  3,  ...,  1,  1,  1]], device='cuda:0', dtype=torch.int8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = AlignIO.read(msa_fp, 'fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = bm.get_seqs(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "582244"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29409"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seqs[list(seqs.keys())[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceData(torch.utils.data.Dataset):\n",
    "    \"\"\"SARS-CoV-2 consensus sequence data.\"\"\"\n",
    "    def __init__(self, fasta_filepath, meta_filepath=None, transforms=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            fasta_filepath (string): Path to the file containing sequences.\n",
    "            meta_filepath (string): Path to the file containing metadata.\n",
    "            transform (callable, optional): Optional transforms to be applied\n",
    "                on a sample e.g. encode_rna().\n",
    "        \"\"\"\n",
    "        # load as generator to save mem\n",
    "        self.samples, self.sequences = self.get_seqs(AlignIO.read(fasta_filepath, 'fasta'))\n",
    "        if meta_filepath:\n",
    "            self.meta = pd.read_csv(meta_filepath, sep='\\t', compression='gzip')\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    # support functions\n",
    "    def get_seqs(self, \n",
    "                 bio_seqs: Align.MultipleSeqAlignment, \n",
    "                 min_pos: int=265, \n",
    "                 max_pos: int=29674) -> dict:\n",
    "        \"\"\"Parse aligned sequences from Bio.Align.MultipleSeqAlignment to list objects.\n",
    "        One list are sample names and the other are their consensus sequences. \n",
    "        Each sequence is trimmed from both ends using `min_pos` and `max_pos`\"\"\"\n",
    "        samples, sequences = [], []\n",
    "        for row in bio_seqs:\n",
    "            samples.append(str(row.id))\n",
    "            s = str(row.seq)\n",
    "            sequences.append(s[min_pos:max_pos])\n",
    "        return samples, sequences\n",
    "        \n",
    "    def encode_rna(self, sequence):\n",
    "        \"encode nucleotide sequence as 4-bit vector\"\n",
    "        code = {\n",
    "                '-': -1,\n",
    "                'N': 0,\n",
    "                'A': 1,\n",
    "                'C': 2,\n",
    "                'T': 3,\n",
    "                'G': 4\n",
    "        }\n",
    "        return [code.get(nt, 0) for nt in sequence]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        sample = self.samples[idx]\n",
    "        sequence = torch.as_tensor(self.encode_rna(self.sequences[idx]),\n",
    "                                   dtype=torch.int8)\n",
    "        # process sample ID (optional)\n",
    "        if self.transforms:\n",
    "            sample = self.transforms(sample)\n",
    "        return sample, sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset object\n",
    "dataset = SequenceData(msa_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Australia/NT12/2020', tensor([1, 3, 4,  ..., 3, 1, 4], dtype=torch.int8))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloader object\n",
    "dataloader = torch.utils.data.DataLoader(data, batch_size=10000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load batch of data\n",
    "x, y = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 3, 4,  ..., 3, 1, 4],\n",
       "        [1, 3, 4,  ..., 3, 1, 4],\n",
       "        [1, 3, 4,  ..., 3, 1, 4],\n",
       "        ...,\n",
       "        [1, 3, 4,  ..., 3, 1, 4],\n",
       "        [1, 3, 4,  ..., 3, 1, 4],\n",
       "        [1, 3, 4,  ..., 3, 1, 4]], device='cuda:0', dtype=torch.int8)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define transform to turn sequences into memory-efficient tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: re-implement bjorn's variant counting as tensor operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicNN(torch.nn.Module):\n",
    "    def __init__(self, num_inputs, num_hidden, num_outputs):\n",
    "        super(BasicNN, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(num_inputs, num_hidden)\n",
    "        self.activation1 = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(num_hidden, num_outputs)\n",
    "        self.final_activation = torch.nn.Softmax()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.linear2(x)\n",
    "        prediction = self.final_activation(x)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
