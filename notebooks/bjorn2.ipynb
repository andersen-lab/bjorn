{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import torch  \n",
    "from Bio import SeqIO, AlignIO\n",
    "import mutations as bm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "Quadro P5000\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_fp = '/valhalla/gisaid/sequences_2021-02-21_aligned.fasta'\n",
    "patient_zero = 'NC_045512.2'\n",
    "seqs = SeqIO.parse(msa_fp, 'fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_rna(sequence: str):\n",
    "    \"encode nucleotide sequence as 4-bit vector\"\n",
    "    code = {\n",
    "            '-': -1,\n",
    "            'N': 0,\n",
    "            'A': 1,\n",
    "            'C': 2,\n",
    "            'T': 3,\n",
    "            'G': 4\n",
    "    }\n",
    "    return [code.get(nt, 0) for nt in sequence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10002"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load sample data from GISAID and encode\n",
    "data = []\n",
    "for i, rec in enumerate(seqs):\n",
    "    data.append(encode_rna(str(rec.seq)))\n",
    "    if i >= 10000:\n",
    "        break\n",
    "# add reference\n",
    "ref = bm.get_seq(seqs, patient_zero)\n",
    "data.append(encode_rna(ref))\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29903"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "max_len = 0\n",
    "for seq in data:\n",
    "    if len(seq)>max_len:\n",
    "        max_len = len(seq)\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29903"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "min_len = 100000\n",
    "for seq in data:\n",
    "    if len(seq)<min_len:\n",
    "        min_len = len(seq)\n",
    "min_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sequences into GPU\n",
    "data_tensor = torch.as_tensor(data, \n",
    "                              dtype=torch.int8, \n",
    "                              device=torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1, -1, -1,  ..., -1, -1, -1],\n",
       "        [-1, -1, -1,  ...,  1,  1,  1],\n",
       "        [-1, -1, -1,  ...,  1,  1,  1],\n",
       "        ...,\n",
       "        [-1, -1, -1,  ..., -1, -1, -1],\n",
       "        [-1, -1, -1,  ..., -1, -1, -1],\n",
       "        [ 1,  3,  3,  ...,  1,  1,  1]], device='cuda:0', dtype=torch.int8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceData(Dataset):\n",
    "    \"\"\"SARS-CoV-2 consensus sequence data.\"\"\"\n",
    "    def __init__(self, fasta_filepath, meta_filepath, transforms=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            fasta_filepath (string): Path to the file containing sequences.\n",
    "            meta_filepath (string): Path to the file containing metadata.\n",
    "            transform (callable, optional): Optional transforms to be applied\n",
    "                on a sample e.g. encode_rna().\n",
    "        \"\"\"\n",
    "        self.meta = pd.read_csv(meta_filepath, sep='\\t', compression='gzip')\n",
    "        # load as generator to save mem\n",
    "        self.sequences = SeqIO.parse(fasta_filepath, 'fasta')\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define transform to turn sequences into memory-efficient tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: re-implement bjorn's variant counting as tensor operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicNN(torch.nn.Module):\n",
    "    def __init__(self, num_inputs, num_hidden, num_outputs):\n",
    "        super(BasicNN, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(num_inputs, num_hidden)\n",
    "        self.activation1 = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(num_hidden, num_outputs)\n",
    "        self.final_activation = torch.nn.Softmax()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.linear2(x)\n",
    "        prediction = self.final_activation(x)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
