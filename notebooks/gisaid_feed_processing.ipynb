{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JSON...\n",
      "Converting to dict...\n",
      "Converting to FASTA...\n",
      "FASTA output generated and saved in /valhalla/gisaid/test.fasta\n"
     ]
    }
   ],
   "source": [
    "# JSON 2 FASTA\n",
    "import re\n",
    "import json\n",
    "import gzip\n",
    "from Bio import SeqIO\n",
    "\n",
    "in_fp = '/valhalla/al_tmp/provision.json'\n",
    "out_fp = '/valhalla/gisaid/test.fasta'\n",
    "regex = re.compile('[^a-zA-Z]')\n",
    "print(f\"Loading JSON...\")\n",
    "data = [json.loads(line) for line in open(in_fp, 'r')]\n",
    "print(f\"Converting to dict...\")\n",
    "seqs_dict = {sample['covv_virus_name'].replace('hCoV-19/', '').replace(' ', ''): \n",
    "             regex.sub('', sample['sequence'].replace('\\n', '')) for sample in data}\n",
    "print(f\"Converting to FASTA...\")\n",
    "with open(out_fp, 'w') as f:\n",
    "    f.write(''.join(f'>{idx}\\n{seq}\\n' for idx, seq in seqs_dict.items()))\n",
    "print(f\"FASTA output generated and saved in {out_fp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import gc\n",
    "import re\n",
    "import json\n",
    "import fiona\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import visualize as bv\n",
    "import data as bd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metacols = ['covv_virus_name', 'covsurver_prot_mutations', 'covv_location',\n",
    "             'covv_lineage', 'covv_collection_date', 'covv_accession_id',\n",
    "             'pangolin_lineages_version', 'covv_clade', 'covv_subm_date']\n",
    "in_fp = '/valhalla/gisaid/2021-02-17.json'\n",
    "# df = pd.read_json('/valhalla/gisaid/2021-02-17.json', lines=True)\n",
    "data = [json.loads(line) for line in open(in_fp, 'r')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "550092"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw sequence parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_fp = '/valhalla/gisaid/raw_sequences_2021-02-17.fasta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict2fasta(seqs: dict, fasta_fp: str, wrap=80):\n",
    "    with open(fasta_fp, 'w') as f:\n",
    "        for gid, gseq in seqs.items():\n",
    "            f.write('>{}\\n'.format(gid))\n",
    "            for i in range(0, len(gseq), wrap):\n",
    "                f.write('{}\\n'.format(gseq[i:i + wrap])) \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to dict...\n",
      "Converting to FASTA...\n",
      "FASTA output generated and saved in /valhalla/gisaid/sequences_2021-02-17.fasta\n"
     ]
    }
   ],
   "source": [
    "print(f\"Converting to dict...\")\n",
    "regex = re.compile('[^a-zA-Z]')\n",
    "seqs_dict = {sample['covv_virus_name'].replace('hCoV-19/', '').replace(' ', ''): \n",
    "             regex.sub('', sample['sequence'].replace('\\n', '')) for sample in data}\n",
    "print(f\"Converting to FASTA...\")\n",
    "dict2fasta(seqs_dict, out_fp)\n",
    "# with open(out_fp, 'w') as f:\n",
    "#     f.write(''.join(f'>{idx}\\n{seq}\\n' for idx, seq in seqs_dict.items()))\n",
    "print(f\"FASTA output generated and saved in {out_fp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLS = [\n",
    "'covv_virus_name', \n",
    "'covv_location', \n",
    "'covv_subm_date',\n",
    "'covv_clade',\n",
    "'covv_lineage',\n",
    "'pangolin_lineages_version',\n",
    "'covv_accession_id'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns=COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['covv_virus_name', 'covv_location', 'covv_subm_date', 'covv_clade',\n",
       "       'covv_lineage', 'pangolin_lineages_version', 'covv_accession_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df['covv_accession_id'].shape[0]==df['covv_accession_id'].unique().shape[0], f'ERROR: gisaid accession ids not unique'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(550092,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['covv_accession_id'].unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\n",
    "                   'covv_virus_name': 'strain', \n",
    "                   'covv_location': 'location', \n",
    "                   'covv_subm_date': 'date_submitted',\n",
    "                   'covv_clade': 'clade',\n",
    "                   'covv_lineage': 'pango_lineage',\n",
    "                   'pangolin_lineages_version': 'pango_version',\n",
    "                   'covv_accession_id': 'accession_id'\n",
    "                  }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_gadm_names(filename, usecols, **kwargs):\n",
    "    with fiona.open(filename, **kwargs) as source:\n",
    "        for feature in source:\n",
    "            f = {k: feature[k] for k in ['id', 'geometry']}\n",
    "            f['properties'] = {k: feature['properties'][k] for k in usecols}\n",
    "            yield f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gadm_fp = '/home/al/data/geojsons/gadm36.shp'\n",
    "gadm = gpd.read_file('/home/al/data/geojsons/gadm36.shp')\n",
    "gadm_cols = [f'NAME_{i}' for i in range(5)]\n",
    "gadm = gadm[gadm_cols]\n",
    "# gpd.GeoDataFrame.from_features(fetch_gadm_names(gadm_fp), gadm_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NAME_0', 'NAME_1', 'NAME_2', 'NAME_3', 'NAME_4'], dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gadm.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(df['location'].str.split('/').tolist(), \n",
    "             columns=['region',\n",
    "                    'country', \n",
    "                    'division', \n",
    "                    'location', \n",
    "                    'city', \n",
    "                    'town'])\n",
    "df['country'] = res['country'].str.strip()\n",
    "df['division'] = res['division'].str.strip()\n",
    "df['location'] = res['location'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>division</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Australia</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>Noord Holland</td>\n",
       "      <td>Diemen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Australia</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Australia</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>Australia</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550087</th>\n",
       "      <td>Poland</td>\n",
       "      <td>Wielkopolskie</td>\n",
       "      <td>Rogierowko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550088</th>\n",
       "      <td>Poland</td>\n",
       "      <td>Wielkopolskie</td>\n",
       "      <td>Skorzewo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550089</th>\n",
       "      <td>Poland</td>\n",
       "      <td>Wielkopolskie</td>\n",
       "      <td>Poznan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550090</th>\n",
       "      <td>Poland</td>\n",
       "      <td>Wielkopolskie</td>\n",
       "      <td>Poznan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550091</th>\n",
       "      <td>Poland</td>\n",
       "      <td>Wielkopolskie</td>\n",
       "      <td>Poznan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87854 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            country         division    location\n",
       "12        Australia  New South Wales      Sydney\n",
       "58      Netherlands    Noord Holland      Diemen\n",
       "128       Australia  New South Wales      Sydney\n",
       "131       Australia  New South Wales      Sydney\n",
       "134       Australia  New South Wales      Sydney\n",
       "...             ...              ...         ...\n",
       "550087       Poland    Wielkopolskie  Rogierowko\n",
       "550088       Poland    Wielkopolskie    Skorzewo\n",
       "550089       Poland    Wielkopolskie      Poznan\n",
       "550090       Poland    Wielkopolskie      Poznan\n",
       "550091       Poland    Wielkopolskie      Poznan\n",
       "\n",
       "[87854 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[~df['location'].isna()][['country', 'division', 'location']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res['country'].value_counts().iloc[:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Admin0 Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['country_normed'] = df['country'].copy()\n",
    "df['country_normed'].fillna('None', inplace=True)\n",
    "df.loc[df['country_normed']=='USA', 'country_normed'] = 'United States'\n",
    "df.loc[df['country_normed'].str.contains('Congo'), 'country_normed'] = 'Republic of Congo'\n",
    "df.loc[df['country_normed'].str.contains('Cote dIvoire'), 'country_normed'] = \"Côte d'Ivoire\"\n",
    "df.loc[df['country_normed'].str.contains('North Macedonia'), 'country_normed'] = \"Macedonia\"\n",
    "df.loc[df['country_normed'].str.contains('Curacao'), 'country_normed'] = \"Curaçao\"\n",
    "df.loc[df['country_normed'].str.contains('Saint Martin'), 'country_normed'] = \"Saint-Martin\"\n",
    "df.loc[df['country_normed'].str.contains('Trinidad'), 'country_normed'] = 'Trinidad and Tobago'\n",
    "df.loc[df['country_normed'].str.contains('Czech republic'), 'country_normed'] = 'Czech Republic'\n",
    "df.loc[df['country_normed'].str.contains('St Eustatius'), 'country_normed'] = 'Netherlands'\n",
    "df.loc[df['country_normed'].str.contains('Saint Barthelemy'), 'country_normed'] = 'Saint-Barthélemy'\n",
    "df.loc[df['country_normed'].str.contains('Palestine'), 'country_normed'] = \"Palestina\"\n",
    "df.loc[df['country_normed'].str.contains(\"Germany /\"), 'country_normed'] = \"Germany\"\n",
    "df.loc[df['country_normed'].str.contains(\"France /Nouvelle-Aquitaine\"), 'division'] = \"Nouvelle-Aquitaine\"\n",
    "df.loc[df['country_normed']==\"France /Nouvelle-Aquitaine\", 'country_normed'] = \"France\"\n",
    "df.loc[df['country_normed'].str.contains(\"France /Nouvelle-Aquitaine/ Limoges\"), 'division'] = \"Nouvelle-Aquitaine\"\n",
    "df.loc[df['country_normed'].str.contains(\"France /Nouvelle-Aquitaine/ Limoges\"), 'location'] = \"Limoges\"\n",
    "df.loc[df['country_normed']==\"France /Nouvelle-Aquitaine/ Limoges\", 'country_normed'] = \"France\"\n",
    "df.loc[df['country_normed']==\"Kenya /\", 'country_normed'] = \"Kenya\"\n",
    "df.loc[df['country_normed']==\"Switzerland/ Schwyz\", 'division'] = \"Schwyz\"\n",
    "df.loc[df['country_normed']==\"Switzerland/ Schwyz\", 'country_normed'] = \"Switzerland\"\n",
    "df.loc[df['country_normed']==\"USA /Wisconsin\", 'division'] = \"Wisconsin\"\n",
    "df.loc[df['country_normed']==\"USA /Wisconsin\", 'country_normed'] = \"United States\"\n",
    "df.loc[df['country_normed']==\"Jonavos apskritis\", 'country_normed'] = \"Lithuania\"\n",
    "df.loc[df['country_normed']==\"Thailand /Singburi\", 'division'] = \"Singburi\"\n",
    "df.loc[df['country_normed']==\"Thailand /Singburi\", 'country_normed'] = \"Thailand\"\n",
    "df.loc[df['country_normed']==\"Norway /\", 'country_normed'] = \"Norway\"\n",
    "df.loc[df['country_normed']==\"Morocoo\", 'country_normed'] = \"Morocco\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sorted(gadm_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153\n",
      "256\n",
      "Number of countries captured in GADM: 151\n",
      "Countries in GISAID not captured in GADM: {'Crimea', 'Caribbean'}\n"
     ]
    }
   ],
   "source": [
    "gisaid_0 = set(df['country_normed'].unique())\n",
    "gadm_0 = set(gadm['NAME_0'].unique())\n",
    "print(len(gisaid_0))\n",
    "print(len(gadm_0))\n",
    "print(f'Number of countries captured in GADM: {len(gisaid_0 & gadm_0)}')\n",
    "print(f'Countries in GISAID not captured in GADM: {gisaid_0 - gadm_0}')\n",
    "#TODO: fix Morocoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples missing country-level geo-information: 19\n"
     ]
    }
   ],
   "source": [
    "missing_countries = ['Crimea', 'Caribbean']\n",
    "samples_missing_country = df[df['country'].isin(missing_countries)]\n",
    "print(f'Number of samples missing country-level geo-information: {samples_missing_country.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Admin1 Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['division'].isna(), 'division'] = 'None'\n",
    "df['division_normed'] = df['division'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sorted(gadm_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "3487\n",
      "28\n",
      "['None', 'Rondonia']\n"
     ]
    }
   ],
   "source": [
    "# TODO: Spain, rest of EU!\n",
    "country = 'Brazil'\n",
    "if country:\n",
    "    gisaid_1 = set(df[df['country']==country]['division_normed'].unique())\n",
    "else:\n",
    "    gisaid_1 = set(df['division_normed'].unique())\n",
    "gadm_1 = set(gadm[~gadm['NAME_1'].isna()]['NAME_1'].unique())\n",
    "print(len(gisaid_1))\n",
    "print(len(gadm_1))\n",
    "print(len(gisaid_1&gadm_1))\n",
    "print(sorted(gisaid_1 - gadm_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['division_normed'] = df['division'].copy()\n",
    "df.loc[df['division_normed']=='USA', 'division_normed'] = 'United States'\n",
    "df.loc[df['division_normed'].str.contains('Georgia /'), 'division_normed'] = 'Georgia'\n",
    "df.loc[df['division_normed'].str.contains('Antwerp'), 'division_normed'] = 'Vlaanderen'\n",
    "df.loc[df['division_normed'].str.contains('Andalu'), 'division_normed'] = 'Andalucía'\n",
    "df.loc[df['division_normed'].str.contains('Cairo'), 'division_normed'] = 'Al Qahirah'\n",
    "df.loc[df['division_normed'].str.contains('Northern territory'), 'division_normed'] = 'Northern Territory'\n",
    "df.loc[df['division_normed'].str.contains('Fayoum'), 'division_normed'] = 'Al Fayyum'\n",
    "df.loc[df['division_normed'].str.contains('Musca'), 'division_normed'] = 'Muscat'\n",
    "df.loc[df['division_normed'].str.contains('Kalyoubia'), 'division_normed'] = 'Al Qalyubiyah'\n",
    "df.loc[df['division_normed'].str.contains('Buraymi'), 'division_normed'] = 'Al Buraymi'\n",
    "df.loc[df['division_normed'].str.contains('Buraimi'), 'division_normed'] = 'Al Buraymi'\n",
    "df.loc[df['division_normed'].str.contains('Dakhiliyah'), 'division_normed'] = 'Ad Dakhliyah'\n",
    "df.loc[df['division_normed'].str.contains('Dhahirah'), 'division_normed'] = 'Al Dhahira'\n",
    "df.loc[df['division_normed'].str.contains('North Batinah'), 'division_normed'] = 'Al Batinah North'\n",
    "df.loc[df['division_normed'].str.contains('South Batinah'), 'division_normed'] = 'Al Batinah South'\n",
    "df.loc[df['division_normed'].str.contains('North Sharqiyah'), 'division_normed'] = 'Ash Sharqiyah North'\n",
    "df.loc[df['division_normed'].str.contains('Wuhan'), 'division_normed'] = 'Hubei'\n",
    "df.loc[df['division_normed'].str.contains('Quebec'), 'division_normed'] = 'Québec'\n",
    "df.loc[df['division_normed'].str.contains('Toronto'), 'division_normed'] = 'Ontario'\n",
    "df.loc[df['division_normed'].str.contains('Coahuila de Zaragoza'), 'division_normed'] = 'Coahuila'\n",
    "df.loc[df['division_normed'].str.contains('Mexico City'), 'division_normed'] = 'México'\n",
    "df.loc[df['division_normed'].str.contains('Michoacan'), 'division_normed'] = 'Michoacán'\n",
    "df.loc[df['division_normed'].str.contains('Nuevo Leon'), 'division_normed'] = 'Nuevo León'\n",
    "df.loc[df['division_normed'].str.contains('Queretaro'), 'division_normed'] = 'Querétaro'\n",
    "df.loc[df['division_normed'].str.contains('SanLuisPotosi'), 'division_normed'] = 'San Luis Potosí'\n",
    "df.loc[df['division_normed'].str.contains('San Luis Potosi'), 'division_normed'] = 'San Luis Potosí'\n",
    "df.loc[df['division_normed'].str.contains('State of Mexico'), 'division_normed'] = 'México'\n",
    "df.loc[df['division_normed'].str.contains('Yucatan'), 'division_normed'] = 'Yucatán'\n",
    "df.loc[df['division_normed'].str.contains('Bethlehem'), 'division_normed'] = 'West Bank'\n",
    "df.loc[df['division_normed'].str.contains('Hebron'), 'division_normed'] = 'West Bank'\n",
    "df.loc[df['division_normed'].str.contains('Jenin'), 'division_normed'] = 'West Bank'\n",
    "df.loc[df['division_normed'].str.contains('Jericho'), 'division_normed'] = 'West Bank'\n",
    "df.loc[df['division_normed'].str.contains('Ramallah'), 'division_normed'] = 'West Bank'\n",
    "df.loc[df['division_normed'].str.contains('Tulkarem'), 'division_normed'] = 'West Bank'\n",
    "df.loc[df['division_normed'].str.contains('Nablus'), 'division_normed'] = 'West Bank'\n",
    "df.loc[df['division_normed'].str.contains('Sharja'), 'division_normed'] = 'Sharjah'\n",
    "df.loc[df['division_normed'].str.contains('Copenhagen'), 'division_normed'] = 'Hovedstaden'\n",
    "df.loc[df['division_normed'].str.contains('Sjaelland'), 'division_normed'] = 'Sjælland'\n",
    "df.loc[df['division_normed'].str.contains('Cape Town'), 'division_normed'] = 'Western Cape'\n",
    "df.loc[df['division_normed'].str.contains('Western Cape'), 'division_normed'] = 'Western Cape'\n",
    "df.loc[df['division_normed'].str.contains('Amapa'), 'division_normed'] = 'Amapá'\n",
    "df.loc[df['division_normed'].str.contains('Ceara'), 'division_normed'] = 'Ceará'\n",
    "df.loc[df['division_normed'].str.contains('Goias'), 'division_normed'] = 'Goiás'\n",
    "df.loc[df['division_normed'].str.contains('Maranhao'), 'division_normed'] = 'Maranhão'\n",
    "df.loc[df['division_normed'].str.contains('Paraiba'), 'division_normed'] = 'Paraíba'\n",
    "df.loc[df['division_normed'].str.contains('Parana'), 'division_normed'] = 'Paraná'\n",
    "df.loc[df['division_normed'].str.contains('Piaui'), 'division_normed'] = 'Piauí'\n",
    "df.loc[df['division_normed'].str.contains('Sao Paulo'), 'division_normed'] = 'São Paulo'\n",
    "df.loc[df['division_normed'].str.contains('Aragon'), 'division_normed'] = 'Aragón'\n",
    "df.loc[df['division_normed'].str.contains('Asturias'), 'division_normed'] = 'Principado de Asturias'\n",
    "df.loc[df['division_normed'].str.contains('Balear Islands'), 'division_normed'] = 'Islas Baleadf'\n",
    "df.loc[df['division_normed'].str.contains('Balear_Islands'), 'division_normed'] = 'Islas Baleadf'\n",
    "df.loc[df['division_normed'].str.contains('Illes Balears'), 'division_normed'] = 'Islas Baleadf'\n",
    "df.loc[df['division_normed'].str.contains('Canary Islands'), 'division_normed'] = 'Canaries'\n",
    "df.loc[df['division_normed'].str.contains('Canary_Islands'), 'division_normed'] = 'Canaries'\n",
    "df.loc[df['division_normed'].str.contains('Castilla La Mancha'), 'division_normed'] = 'Castilla-La Mancha'\n",
    "df.loc[df['division_normed'].str.contains('Castilla la Mancha'), 'division_normed'] = 'Castilla-La Mancha'\n",
    "df.loc[df['division_normed'].str.contains('Castilla y Leon'), 'division_normed'] = 'Castilla y León'\n",
    "df.loc[df['division_normed'].str.contains('Ceuta'), 'division_normed'] = 'Ceuta y Melilla'\n",
    "df.loc[df['division_normed'].str.contains('Melilla'), 'division_normed'] = 'Ceuta y Melilla'\n",
    "df.loc[df['division_normed'].str.contains('Comunitat Valenciana'), 'division_normed'] = 'Comunidad Valenciana'\n",
    "df.loc[df['division_normed'].str.contains('Comunitat_Valenciana'), 'division_normed'] = 'Comunidad Valenciana'\n",
    "df.loc[df['division_normed'].str.contains('La_Rioja'), 'division_normed'] = 'La Rioja'\n",
    "df.loc[df['division_normed'].str.contains('Madrid'), 'division_normed'] = 'Comunidad de Madrid'\n",
    "df.loc[df['division_normed'].str.contains('Murcia'), 'division_normed'] = 'Región de Murcia'\n",
    "df.loc[df['division_normed'].str.contains('Navarra'), 'division_normed'] = 'Comunidad Foral de Navarra'\n",
    "df.loc[df['division_normed'].str.contains('Catalunya'), 'division_normed'] = 'Cataluña'\n",
    "df.loc[df['division_normed'].str.contains('Catalonia'), 'division_normed'] = 'Cataluña'\n",
    "df.loc[df['division_normed'].str.contains('Baden-Wuerttemberg'), 'division_normed'] = 'Baden-Württemberg'\n",
    "df.loc[df['division_normed'].str.contains('Baden-Wurttemberg'), 'division_normed'] = 'Baden-Württemberg'\n",
    "df.loc[df['division_normed'].str.contains('Bavaria'), 'division_normed'] = 'Bayern'\n",
    "df.loc[df['division_normed'].str.contains('Hesse'), 'division_normed'] = 'Hessen'\n",
    "df.loc[df['division_normed'].str.contains('Lower Saxony'), 'division_normed'] = 'Niedersachsen'\n",
    "df.loc[df['division_normed'].str.contains('Mecklenburg-Western Pomerania'), 'division_normed'] = 'Mecklenburg-Vorpommern'\n",
    "df.loc[df['division_normed'].str.contains('Rhineland-Palatinate'), 'division_normed'] = 'Rheinland-Pfalz'\n",
    "df.loc[df['division_normed'].str.contains('Saxony'), 'division_normed'] = 'Sachsen'\n",
    "df.loc[df['division_normed'].str.contains('Saxony-Anhalt'), 'division_normed'] = 'Sachsen-Anhalt'\n",
    "df.loc[df['division_normed'].str.contains('North Rhine-Westphalia'), 'division_normed'] = 'Nordrhein-Westfalen'\n",
    "df.loc[df['division_normed'].str.contains('Thuringia'), 'division_normed'] = 'Thüringen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['United Arab Emirates'], dtype=object)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['country'].str.contains('Emirates'), 'country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sorted(gadm_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrections = bd.COUNTY_CORRECTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res['location'] = res['location'].str.replace(',', '').str[:-2]\n",
    "df.loc[df['location'].isna(), 'location'] = 'None'\n",
    "df['location_normed'] = df['location'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in corrections.items():\n",
    "    df.loc[:, 'location_normed'] = df['location_normed'].str.replace(key, val)\n",
    "df.loc[:, 'location_normed'] = df['location_normed'].str.replace('County', '').str.replace('county', '').str.replace(',', '')\n",
    "df.loc[:, 'location_normed'] = df['location_normed'].str.strip().apply(bv.check_state, args=(False,)).str.strip()\n",
    "df.loc[df['location_normed'].str.contains('Anchorage-Mat-Su'), 'location_normed'] = 'Anchorage'\n",
    "df.loc[df['location_normed'].str.contains('Anchorage-Mat Su'), 'location_normed'] = 'Anchorage'\n",
    "df.loc[df['location_normed'].str.contains('BRA'), 'location_normed'] = 'Brazos'\n",
    "df.loc[df['location_normed'].str.contains('BR'), 'location_normed'] = 'Brewster'\n",
    "df.loc[df['location_normed'].str.contains('Belgrade'), 'location_normed'] = 'Gallatin'\n",
    "df.loc[df['location_normed'].str.contains('Bozeman'), 'location_normed'] = 'Gallatin'\n",
    "df.loc[df['location_normed'].str.contains('Big Sky'), 'location_normed'] = 'Gallatin'\n",
    "df.loc[df['location_normed'].str.contains('Belton'), 'location_normed'] = 'Bell'\n",
    "df.loc[df['location_normed'].str.contains('Brentwood'), 'location_normed'] = 'Contra Costa'\n",
    "df.loc[df['location_normed'].str.contains('Chicago'), 'location_normed'] = 'Cook'\n",
    "df.loc[df['location_normed'].str.contains('Colombus'), 'location_normed'] = 'Franklin'\n",
    "df.loc[df['location_normed'].str.contains('DuBois'), 'location_normed'] = 'Fremont'\n",
    "df.loc[df['location_normed'].str.contains('DuPage'), 'location_normed'] = 'Dupage'\n",
    "df.loc[df['location_normed'].str.contains('Eau claire'), 'location_normed'] = 'Eau Claire'\n",
    "df.loc[df['location_normed'].str.contains('Ennis'), 'location_normed'] = 'Ellis'\n",
    "df.loc[df['location_normed'].str.contains('Fond Du Lac'), 'location_normed'] = 'Fond du Lac'\n",
    "df.loc[df['location_normed'].str.contains('Fond du lac'), 'location_normed'] = 'Fond du Lac'\n",
    "df.loc[df['location_normed'].str.contains('Fonddu Lac'), 'location_normed'] = 'Fond du Lac'\n",
    "df.loc[df['location_normed'].str.contains('Frisco'), 'location_normed'] = 'Collin'\n",
    "df.loc[df['location_normed'].str.contains('Hawai'), 'location_normed'] = 'Hawaii'\n",
    "df.loc[df['location_normed'].str.contains('Holland'), 'location_normed'] = 'Ottawa'\n",
    "df.loc[df['location_normed'].str.contains('Honolul'), 'location_normed'] = 'Honolulu'\n",
    "df.loc[df['location_normed'].str.contains('Indianapolis'), 'location_normed'] = 'Marion'\n",
    "df.loc[df['location_normed'].str.contains('Interior'), 'location_normed'] = 'Fairbanks North Star'\n",
    "df.loc[df['location_normed'].str.contains('Ithaca'), 'location_normed'] = 'Tompkins'\n",
    "df.loc[df['location_normed'].str.contains('Kaua'), 'location_normed'] = 'Kauai'\n",
    "df.loc[df['location_normed'].str.contains('Las Vegas'), 'location_normed'] = 'Clark'\n",
    "df.loc[df['location_normed'].str.contains('Mau'), 'location_normed'] = 'Hawaii'\n",
    "df.loc[df['location_normed'].str.contains('Mcculloch'), 'location_normed'] = 'McCulloch'\n",
    "df.loc[df['location_normed'].str.contains('Mchenry'), 'location_normed'] = 'McHenry'\n",
    "df.loc[df['location_normed'].str.contains('Mclennan'), 'location_normed'] = 'McLennan'\n",
    "df.loc[df['location_normed'].str.contains('Moris'), 'location_normed'] = 'Morris'\n",
    "df.loc[df['location_normed'].str.contains('New York'), 'location_normed'] = 'New York'\n",
    "df.loc[df['location_normed'].str.contains('New York City'), 'location_normed'] = 'New York'\n",
    "df.loc[df['location_normed'].str.contains('New Hyde Park'), 'location_normed'] = 'Nassau'\n",
    "df.loc[df['location_normed'].str.contains('New Orleans'), 'location_normed'] = 'Orleans'\n",
    "df.loc[df['location_normed'].str.contains('New Rochelle'), 'location_normed'] = 'Westchester'\n",
    "df.loc[df['location_normed'].str.contains('Northern'), 'location_normed'] = 'Fairbanks North Star'\n",
    "df.loc[df['location_normed'].str.contains('Omaha'), 'location_normed'] = 'Douglas'\n",
    "df.loc[df['location_normed'].str.contains('Ostego'), 'location_normed'] = 'Allegan'\n",
    "df.loc[df['location_normed'].str.contains('Phoenix'), 'location_normed'] = 'Maricopa'\n",
    "df.loc[df['location_normed'].str.contains('San Bernadino'), 'location_normed'] = 'San Bernardino'\n",
    "df.loc[df['location_normed'].str.contains('Seattle'), 'location_normed'] = 'King'\n",
    "df.loc[df['location_normed'].str.contains('St. Bernard'), 'location_normed'] = 'Saint Bernard'\n",
    "df.loc[df['location_normed'].str.contains('St. Clair'), 'location_normed'] = 'Saint Clair'\n",
    "df.loc[df['location_normed'].str.contains('St. Lawrence'), 'location_normed'] = 'Saint Lawrence'\n",
    "df.loc[df['location_normed'].str.contains('St. Louis'), 'location_normed'] = 'Saint Louis'\n",
    "df.loc[df['location_normed'].str.contains('St. Tammany'), 'location_normed'] = 'Saint Tammany'\n",
    "df.loc[df['location_normed'].str.contains('Staten Island'), 'location_normed'] = 'Richmond'\n",
    "df.loc[df['location_normed'].str.contains('Thurson'), 'location_normed'] = 'Thurston'\n",
    "df.loc[df['location_normed'].str.contains('Tucson'), 'location_normed'] = 'Pima'\n",
    "df.loc[df['location_normed'].str.contains('West Yellowstone'), 'location_normed'] = 'Gallatin'\n",
    "df.loc[df['location_normed'].str.contains('Adam'), 'location_normed'] = 'Adams'\n",
    "df.loc[df['location_normed'].str.contains('Alachu'), 'location_normed'] = 'Alachua'\n",
    "df.loc[df['location_normed'].str.contains('Du Bois'), 'location_normed'] = 'Dubois'\n",
    "df.loc[df['location_normed'].str.contains('DeSoto'), 'location_normed'] = 'Desoto'\n",
    "df.loc[df['location_normed'].str.contains('PdfID'), 'location_normed'] = 'Pdfidio'\n",
    "df.loc[df['location_normed'].str.contains('LaSalle'), 'location_normed'] = 'La Salle'\n",
    "df.loc[df['location_normed'].str.contains('CAMER'), 'location_normed'] = 'Cameron'\n",
    "df.loc[df['location_normed'].str.contains('CAST'), 'location_normed'] = 'Castro'\n",
    "df.loc[df['location_normed'].str.contains('CROS'), 'location_normed'] = 'Crosby'\n",
    "df.loc[df['location_normed'].str.contains('ECT'), 'location_normed'] = 'Ector'\n",
    "df.loc[df['location_normed'].str.contains('GALVEST'), 'location_normed'] = 'Galveston'\n",
    "df.loc[df['location_normed'].str.contains('JEFFERS'), 'location_normed'] = 'Jefferson'\n",
    "df.loc[df['location_normed'].str.contains('KAUFM'), 'location_normed'] = 'Kaufman'\n",
    "df.loc[df['location_normed'].str.contains('KLEBE'), 'location_normed'] = 'Kleberg'\n",
    "df.loc[df['location_normed'].str.contains('LAVA'), 'location_normed'] = 'Lavaca'\n",
    "df.loc[df['location_normed'].str.contains('MCLENN'), 'location_normed'] = 'Mclennan'\n",
    "df.loc[df['location_normed'].str.contains('St.Clair'), 'location_normed'] = 'Saint Clair'\n",
    "df.loc[df['location_normed'].str.contains('TARRA'), 'location_normed'] = 'Tarrant'\n",
    "df.loc[df['location_normed'].str.contains('WALL'), 'location_normed'] = 'Waller'\n",
    "df.loc[df['location_normed'].str.contains('WICHI'), 'location_normed'] = 'Wichita'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506\n",
      "1840\n",
      "484\n",
      "['', 'Ambulance', 'Gulf Coast', 'HA', 'M', 'Mclennan', 'Nan', 'Napa Solano Yolo Marin Counties', 'None', 'Out Of State', 'Out of state', 'Out-Of-State', 'Out-of-state', 'PRESID', 'Ponce', 'South West', 'Southeast', 'Southwest', 'UNKNO', 'Unknown', 'Western Alaska', 'unknown']\n"
     ]
    }
   ],
   "source": [
    "# TODO: Mexico, China, Jordan, Canada\n",
    "country = 'USA'\n",
    "if country:\n",
    "    gisaid_2 = set(df[df['country']==country]['location_normed'].unique())\n",
    "else:\n",
    "    gisaid_2 = set(df['location_normed'].unique())\n",
    "gadm_2 = set(gadm[(~gadm['NAME_2'].isna())&(gadm['NAME_0']=='United States')]['NAME_2'].unique())\n",
    "print(len(gisaid_2))\n",
    "print(len(gadm_2))\n",
    "print(len(gisaid_2&gadm_2))\n",
    "print(sorted(gisaid_2 - gadm_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc[df['location_normed'].str.contains('WICHI')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples missing country-level geo-information: 183\n"
     ]
    }
   ],
   "source": [
    "locs_missing = ['', 'GulfCoast', 'Nan', 'Napa,Solano,Yolo,MarinCounties', \n",
    "                'Out-Of-State', 'Out-of-state', 'OutOfState', \n",
    "                'Outofstate', 'Ponce', 'SouthWest', 'Southeast', \n",
    "                'Southwest', 'Unknown', 'WesternAlaska', 'unknown']\n",
    "samples_missing_county = df.loc[(df['location_normed'].isin(locs_missing))&(df['country']=='USA')]\n",
    "print(f'Number of samples missing country-level geo-information: {samples_missing_county.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None                                                                                                                                                                                                                                                                                                                                                                                                                       462238\n",
       "Houston                                                                                                                                                                                                                                                                                                                                                                                                                     12615\n",
       "Santa Clara County                                                                                                                                                                                                                                                                                                                                                                                                           2282\n",
       "San Diego                                                                                                                                                                                                                                                                                                                                                                                                                    2117\n",
       "Yakima County                                                                                                                                                                                                                                                                                                                                                                                                                2031\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                            ...  \n",
       "La Libertad                                                                                                                                                                                                                                                                                                                                                                                                                     1\n",
       "Rouziers-de-Touraine                                                                                                                                                                                                                                                                                                                                                                                                            1\n",
       "Veltrusy                                                                                                                                                                                                                                                                                                                                                                                                                        1\n",
       "Achenkirch, Aschau im Zillertal, Brandberg, Bruck am Ziller, Buch in Tirol, Eben am Achensee, Finkenberg, Fügen, Fügenberg, Gallzein, Gerlos, Gerlosberg, Hainzenberg, Hart im Zillertal, Hippach, Jenbach, Kaltenbach, Mayrhofen, Ramsau im Zillertal, Ried im Zillertal, Rohrberg, Schlitters, Schwendau, Steinberg am Rofan, Strass im Zillertal, Stumm, Stummerberg, Tux, Uderns, Wiesing, Zell am Ziller, Zellberg         1\n",
       "Kannaland                                                                                                                                                                                                                                                                                                                                                                                                                       1\n",
       "Name: location, Length: 3248, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "England                  190952\n",
       "None                      37951\n",
       "Wales                     26387\n",
       "Hovedstaden               17171\n",
       "Texas                     15897\n",
       "                          ...  \n",
       "Callenelle                    1\n",
       "Montignies-sur-sambre         1\n",
       "Ghlin                         1\n",
       "Rishpon                       1\n",
       "Hertain                       1\n",
       "Name: division, Length: 2359, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['division'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "United Kingdom                      235806\n",
       "USA                                 106640\n",
       "Denmark                              41985\n",
       "Australia                            17368\n",
       "Japan                                17253\n",
       "                                     ...  \n",
       "Andorra                                  1\n",
       "Antigua and Barbuda                      1\n",
       "Albania                                  1\n",
       "Saint Vincent and the Grenadines         1\n",
       "Trinidad and Tobago                      1\n",
       "Name: country, Length: 158, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_fp = '/valhalla/gisaid/meta_2021-02-17.tsv.gz'\n",
    "df.to_csv(meta_fp, sep='\\t', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['strain', 'location', 'date_submitted', 'clade', 'pango_lineage',\n",
       "       'pango_version', 'accession_id', 'country', 'division',\n",
       "       'country_normed', 'division_normed', 'location_normed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bjorn",
   "language": "python",
   "name": "bjorn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
